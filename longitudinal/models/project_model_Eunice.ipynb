{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from longitudinal.settings.constants import DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3636, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH + \"gen1_train_comp_final.csv\")\n",
    "is_gen1 = True\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lb/pskgtvls62dbtqb4_b8_f_8c0000gn/T/ipykernel_45282/4260760116.py:142: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  child_features_train = gen2_train.groupby(\"gen2_id\").apply(\n",
      "/var/folders/lb/pskgtvls62dbtqb4_b8_f_8c0000gn/T/ipykernel_45282/4260760116.py:146: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  child_features_test = gen2_test.groupby(\"gen2_id\").apply(\n",
      "/var/folders/lb/pskgtvls62dbtqb4_b8_f_8c0000gn/T/ipykernel_45282/4260760116.py:151: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  parent_features_train = gen1_train.groupby(\"gen1_id\").apply(\n",
      "/var/folders/lb/pskgtvls62dbtqb4_b8_f_8c0000gn/T/ipykernel_45282/4260760116.py:155: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  parent_features_test = gen1_test.groupby(\"gen1_id\").apply(\n",
      "/var/folders/lb/pskgtvls62dbtqb4_b8_f_8c0000gn/T/ipykernel_45282/4260760116.py:171: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_data.fillna(method='ffill', inplace=True)\n",
      "/var/folders/lb/pskgtvls62dbtqb4_b8_f_8c0000gn/T/ipykernel_45282/4260760116.py:172: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_data.fillna(method='bfill', inplace=True)\n",
      "/var/folders/lb/pskgtvls62dbtqb4_b8_f_8c0000gn/T/ipykernel_45282/4260760116.py:181: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test_data.fillna(method='ffill', inplace=True)\n",
      "/var/folders/lb/pskgtvls62dbtqb4_b8_f_8c0000gn/T/ipykernel_45282/4260760116.py:182: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test_data.fillna(method='bfill', inplace=True)\n",
      "/var/folders/lb/pskgtvls62dbtqb4_b8_f_8c0000gn/T/ipykernel_45282/4260760116.py:200: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  target_train = target_train.fillna(method='ffill').fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "def preprocess_data(df, is_gen1=True):\n",
    "    \"\"\"\n",
    "    Preprocesses the data for both generation 1 and 2 datasets\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove columns that are completely missing\n",
    "    df = df.dropna(axis=1, how=\"all\")\n",
    "\n",
    "    # Ensure only numeric columns are passed to imputer\n",
    "    numeric_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "    df_numeric = df[numeric_cols]\n",
    "\n",
    "    # Apply IterativeImputer\n",
    "    df_imputer = IterativeImputer(max_iter=10, random_state=0, min_value=0, initial_strategy=\"mean\")\n",
    "    df_imputed = pd.DataFrame(df_imputer.fit_transform(df_numeric), columns=df_numeric.columns)\n",
    "\n",
    "    # Restore categorical columns if necessary\n",
    "    df_final = df.copy()\n",
    "    df_final[df_numeric.columns] = df_imputed\n",
    "\n",
    "    # Round ages and convert to int\n",
    "    age_col = 'age' if is_gen1 else 'AgeGr'\n",
    "    df[age_col] = df[age_col].round().astype(int)\n",
    "\n",
    "    # try:\n",
    "    #     df['sex_assigned_at_birth'] = df['sex_assigned_at_birth'].map({'M': 1, 'F': 0})\n",
    "    # except:\n",
    "    #     pass\n",
    "    # try:\n",
    "    #     df['sex_assigned_at_birth'] = df['sex_assigned_at_birth'].map({'M': 1, 'F': 0})\n",
    "    # except:\n",
    "    #     pass\n",
    "    # try:\n",
    "    #     df['study_parent_sex'] = df['study_parent_sex'].map({'mother': 1, 'father': 0})\n",
    "    # except:\n",
    "    #     pass\n",
    "    \n",
    "\n",
    "    # df_imputer = IterativeImputer(max_iter=10, random_state=0, min_value=0, initial_strategy=\"mean\")\n",
    "    # df = pd.DataFrame(df_imputer.fit_transform(df), columns=df.columns)\n",
    "    \n",
    "    # Group columns\n",
    "    group_cols = ['gen1_id', 'sex_assigned_at_birth', 'age'] if is_gen1 else \\\n",
    "                ['gen2_id', 'sex_assigned_at_birth', 'study_parent_sex', 'study_parent_id_new', 'AgeGr']\n",
    "    \n",
    "    # Group and calculate mean\n",
    "    df = df.groupby(group_cols, as_index=False).mean()\n",
    "    \n",
    "    # Sort and interpolate\n",
    "    sort_cols = ['gen1_id', 'age'] if is_gen1 else ['gen2_id', 'AgeGr']\n",
    "    id_col = 'gen1_id' if is_gen1 else 'gen2_id'\n",
    "    \n",
    "    df = df.sort_values(by=sort_cols)\n",
    "    df_grouped = df.groupby(id_col)\n",
    "    \n",
    "    # Interpolate height\n",
    "    df[\"SHgt_cm_CLEANED\"] = df_grouped[\"SHgt_cm\"].apply(lambda x: x.interpolate(method=\"linear\")).bfill().values\n",
    "    \n",
    "    # Interpolate weight for gen2 only\n",
    "    if not is_gen1:\n",
    "        df[\"Wgt_kg_CLEANED\"] = df_grouped[\"Wgt_kg\"].apply(lambda x: x.interpolate(method=\"linear\")).bfill().values\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    df['sex_assigned_at_birth'] = df['sex_assigned_at_birth'].map({'F': 0, 'M': 1})\n",
    "    if not is_gen1:\n",
    "        df['study_parent_sex'] = df['study_parent_sex'].map({'father': 0, 'mother': 1})\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_features(df, prefix, ages, age_column):\n",
    "    \"\"\"\n",
    "    Extract features like height at specific ages and growth velocity\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    for age in ages:\n",
    "        height_at_age = df[df[age_column] == age][\"SHgt_cm_CLEANED\"].values\n",
    "        if len(height_at_age) > 0:\n",
    "            features[f\"{prefix}_height_age_{age}\"] = height_at_age[0]\n",
    "        else:\n",
    "            features[f\"{prefix}_height_age_{age}\"] = np.nan\n",
    "    \n",
    "    # Add growth velocity features\n",
    "    if len(ages) > 1:\n",
    "        for i in range(len(ages)-1):\n",
    "            age1, age2 = ages[i], ages[i+1]\n",
    "            height1 = features.get(f\"{prefix}_height_age_{age1}\")\n",
    "            height2 = features.get(f\"{prefix}_height_age_{age2}\")\n",
    "            if height1 is not None and height2 is not None and not (np.isnan(height1) or np.isnan(height2)):\n",
    "                features[f\"{prefix}_velocity_{age1}_{age2}\"] = (height2 - height1) / (age2 - age1)\n",
    "    \n",
    "    return pd.Series(features)\n",
    "\n",
    "def format_predictions(predictions, gen2_ids):\n",
    "    \"\"\"\n",
    "    Format predictions into the required output format:\n",
    "    gen2id_age SHgt_cm\n",
    "    \"\"\"\n",
    "    formatted_rows = []\n",
    "    prediction_ages = [10, 11, 12, 13, 14, 15, 16, 18]  # Excluding age 17\n",
    "    \n",
    "    for idx, gen2_id in enumerate(gen2_ids):\n",
    "        for col_idx, age in enumerate(prediction_ages):\n",
    "            row_id = f\"{gen2_id}_{age}\"\n",
    "            height = predictions[idx, col_idx]\n",
    "            formatted_rows.append([row_id, height])\n",
    "    \n",
    "    formatted_df = pd.DataFrame(formatted_rows, columns=['gen2id_age', 'SHgt_cm'])\n",
    "    return formatted_df\n",
    "\n",
    "# Load data\n",
    "gen1_train = pd.read_csv(DATA_PATH + \"gen1_train_comp_final.csv\")\n",
    "gen2_train = pd.read_csv(DATA_PATH + \"gen2_train_comp_final.csv\")\n",
    "gen1_test = pd.read_csv(DATA_PATH + \"gen1_test_comp_final.csv\")\n",
    "gen2_test = pd.read_csv(DATA_PATH + \"gen2_test_upto9_comp_final.csv\")\n",
    "\n",
    "# Fix inconsistent study_parent_sex values\n",
    "# There 'study_parent_sex' not consistent over time\n",
    "no_match_kids_0 = gen2_train[gen2_train['gen2_id'].isin([1332, 2505])]\n",
    "no_match_kids_1 = gen2_train[gen2_train['gen2_id'].isin([2517, 3012])] \n",
    "\n",
    "gen2_train.loc[gen2_train['gen2_id'].isin([1332, 2505]), 'study_parent_sex'] = 0\n",
    "gen2_train.loc[gen2_train['gen2_id'].isin([2517, 3012]), 'study_parent_sex'] = 1\n",
    "\n",
    "# Preprocess data\n",
    "gen1_train = preprocess_data(gen1_train, is_gen1=True)\n",
    "gen2_train = preprocess_data(gen2_train, is_gen1=False)\n",
    "gen1_test = preprocess_data(gen1_test, is_gen1=True)\n",
    "gen2_test = preprocess_data(gen2_test, is_gen1=False)\n",
    "\n",
    "# Extract features\n",
    "child_ages = range(0, 10)\n",
    "\n",
    "# Convert age ranges to integers and handle edge cases\n",
    "min_parent_age = int(min(gen1_train['age'].min(), gen1_test['age'].min()))\n",
    "max_parent_age = int(max(gen1_train['age'].max(), gen1_test['age'].max()))\n",
    "parent_ages = list(range(min_parent_age, max_parent_age + 1))\n",
    "\n",
    "# Extract features for children\n",
    "child_features_train = gen2_train.groupby(\"gen2_id\").apply(\n",
    "    extract_features, prefix=\"child\", ages=child_ages, age_column=\"AgeGr\"\n",
    ").reset_index()\n",
    "\n",
    "child_features_test = gen2_test.groupby(\"gen2_id\").apply(\n",
    "    extract_features, prefix=\"child\", ages=child_ages, age_column=\"AgeGr\"\n",
    ").reset_index()\n",
    "\n",
    "# Extract features for parents\n",
    "parent_features_train = gen1_train.groupby(\"gen1_id\").apply(\n",
    "    extract_features, prefix=\"parent\", ages=parent_ages, age_column=\"age\"\n",
    ").reset_index()\n",
    "\n",
    "parent_features_test = gen1_test.groupby(\"gen1_id\").apply(\n",
    "    extract_features, prefix=\"parent\", ages=parent_ages, age_column=\"age\"\n",
    ").reset_index()\n",
    "\n",
    "# Get parent IDs for linking\n",
    "parent_ids_train = gen2_train[['gen2_id', 'study_parent_id_new']].drop_duplicates()\n",
    "parent_ids_test = gen2_test[['gen2_id', 'study_parent_id_new']].drop_duplicates()\n",
    "\n",
    "# Merge features\n",
    "train_data = pd.merge(child_features_train, parent_ids_train, on='gen2_id')\n",
    "train_data = pd.merge(train_data, parent_features_train, \n",
    "                     left_on='study_parent_id_new', \n",
    "                     right_on='gen1_id', \n",
    "                     how='left')\n",
    "    \n",
    "train_data.interpolate(method='linear', inplace=True)  \n",
    "train_data.fillna(method='ffill', inplace=True)\n",
    "train_data.fillna(method='bfill', inplace=True) \n",
    "\n",
    "test_data = pd.merge(child_features_test, parent_ids_test, on='gen2_id')\n",
    "test_data = pd.merge(test_data, parent_features_test,\n",
    "                    left_on='study_parent_id_new',\n",
    "                    right_on='gen1_id',\n",
    "                    how='left')\n",
    "\n",
    "test_data.interpolate(method='linear', inplace=True)\n",
    "test_data.fillna(method='ffill', inplace=True)\n",
    "test_data.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Prepare target variables\n",
    "target_ages = [10, 11, 12, 13, 14, 15, 16, 18]\n",
    "target_train = gen2_train[gen2_train[\"AgeGr\"].isin(target_ages)].pivot(\n",
    "    index=\"gen2_id\", \n",
    "    columns=\"AgeGr\", \n",
    "    values=\"SHgt_cm_CLEANED\"\n",
    ")\n",
    "\n",
    "# Ensure all required ages are present\n",
    "for age in target_ages:\n",
    "    if age not in target_train.columns:\n",
    "        target_train[age] = np.nan\n",
    "\n",
    "# Sort columns and interpolate\n",
    "target_train = target_train.reindex(columns=target_ages)\n",
    "target_train = target_train.interpolate(axis=1, method='linear')\n",
    "target_train = target_train.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# Remove any columns with all NaN values\n",
    "train_data = train_data.dropna(axis=1, how='all')\n",
    "test_data = test_data.dropna(axis=1, how='all')\n",
    "\n",
    "# Align features between train and test sets\n",
    "common_columns = list(set(train_data.columns) & set(test_data.columns))\n",
    "train_data = train_data[common_columns]\n",
    "test_data = test_data[common_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_data.drop(['gen2_id', 'study_parent_id_new', 'gen1_id'], axis=1, errors='ignore'),\n",
    "    target_train,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'subsample': 1.0, 'reg_lambda': 1.0, 'reg_alpha': 0.01, 'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.6}\n",
      "Best MAE: 4.955441474914551\n",
      "Test MAE: 4.26 cm\n",
      "Test RMSE: 6.03 cm\n",
      "MSE: 36.822608947753906\n",
      "Process completed successfully!\n",
      "Final predictions shape: (704, 2)\n",
      "\n",
      "First few predictions:\n",
      "  gen2id_age     SHgt_cm\n",
      "0    2332_10  128.413208\n",
      "1    2332_11  134.490616\n",
      "2    2332_12  140.101913\n",
      "3    2332_13  144.901367\n",
      "4    2332_14  150.920502\n",
      "5    2332_15  153.667099\n",
      "6    2332_16  158.042175\n",
      "7    2332_18  160.882416\n",
      "8    2503_10  139.112305\n",
      "9    2503_11  142.112961\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],  # Number of boosting rounds\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1, 0.2],  # Step size shrinkage\n",
    "    \"max_depth\": [3, 5, 7, 9],  # Maximum depth of trees\n",
    "    \"subsample\": [0.6, 0.8, 1.0],  # Fraction of samples used per tree\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],  # Fraction of features used per tree\n",
    "    \"gamma\": [0, 0.1, 0.2, 0.3],  # Minimum loss reduction required to make a split\n",
    "    \"reg_alpha\": [0, 0.01, 0.1, 1.0],  # L1 regularization\n",
    "    \"reg_lambda\": [1.0, 2.0, 5.0]  # L2 regularization\n",
    "}\n",
    "\n",
    "model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=30, \n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "print(\"Best MAE:\", -random_search.best_score_)\n",
    "\n",
    "\n",
    "model = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42, **random_search.best_params_)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = model.predict(X_val)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(f\"Test MAE: {mae:.2f} cm\")\n",
    "print(f\"Test RMSE: {rmse:.2f} cm\")\n",
    "\n",
    "multi_output_model = MultiOutputRegressor(model)\n",
    "multi_output_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = multi_output_model.predict(X_val)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "print(f\"MSE: {mse}\")\n",
    "\n",
    "# Make predictions on test data\n",
    "test_features = test_data.drop(['gen2_id', 'study_parent_id_new', 'gen1_id'], axis=1, errors='ignore')\n",
    "test_predictions = multi_output_model.predict(test_features)\n",
    "\n",
    "# Format and save predictions\n",
    "formatted_predictions = format_predictions(\n",
    "    predictions=test_predictions,\n",
    "    gen2_ids=test_data['gen2_id']\n",
    ")\n",
    "\n",
    "# Round heights to 2 decimal places\n",
    "formatted_predictions['SHgt_cm'] = formatted_predictions['SHgt_cm']\n",
    "\n",
    "# Save predictions\n",
    "# formatted_predictions.to_csv(\"test_predictions.csv\", index=False)\n",
    "\n",
    "print(\"Process completed successfully!\")\n",
    "print(f\"Final predictions shape: {formatted_predictions.shape}\")\n",
    "print(\"\\nFirst few predictions:\")\n",
    "print(formatted_predictions.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_predictions.to_csv(\"wh_xgboost_submission_2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(704, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(DATA_PATH + \"gen2_test_solution_template.csv\")\n",
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.merge(formatted_predictions, on=\"gen2id_age\", how=\"inner\").drop(columns=[\"SHgt_cm_x\"]).rename(columns={\"SHgt_cm_y\": \"SHgt_cm\"}).to_csv(\"wh_xgboost_submission_2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
